{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SL Assignment 2 - Question 2 NER using LSTM.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPloCFFQPNis",
        "outputId": "1e262b98-0ce7-433c-b817-b47f12dfc3bb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QySEHSyXokp"
      },
      "source": [
        "# **References** - \n",
        "1. https://towardsdatascience.com/named-entity-recognition-ner-using-keras-bidirectional-lstm-28cd3f301f54\n",
        "\n",
        "2. https://www.kaggle.com/dvircohen0/ner-lstm/comments?select=ner_dataset.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRQVwwFwahyi"
      },
      "source": [
        "# **Load and Prepare the data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjbaD-pxPZW8",
        "outputId": "9b8fa021-61a9-400f-ee61-c28d3bd3cbb2"
      },
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('/content/gdrive/MyDrive/Sequence Learning Assignments/ner_dataset.csv', encoding = \"ISO-8859-1\")\n",
        "print(data.shape)\n",
        "print(data.head(30))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1048575, 4)\n",
            "     Sentence #           Word  POS    Tag\n",
            "0   Sentence: 1      Thousands  NNS      O\n",
            "1           NaN             of   IN      O\n",
            "2           NaN  demonstrators  NNS      O\n",
            "3           NaN           have  VBP      O\n",
            "4           NaN        marched  VBN      O\n",
            "5           NaN        through   IN      O\n",
            "6           NaN         London  NNP  B-geo\n",
            "7           NaN             to   TO      O\n",
            "8           NaN        protest   VB      O\n",
            "9           NaN            the   DT      O\n",
            "10          NaN            war   NN      O\n",
            "11          NaN             in   IN      O\n",
            "12          NaN           Iraq  NNP  B-geo\n",
            "13          NaN            and   CC      O\n",
            "14          NaN         demand   VB      O\n",
            "15          NaN            the   DT      O\n",
            "16          NaN     withdrawal   NN      O\n",
            "17          NaN             of   IN      O\n",
            "18          NaN        British   JJ  B-gpe\n",
            "19          NaN         troops  NNS      O\n",
            "20          NaN           from   IN      O\n",
            "21          NaN           that   DT      O\n",
            "22          NaN        country   NN      O\n",
            "23          NaN              .    .      O\n",
            "24  Sentence: 2       Families  NNS      O\n",
            "25          NaN             of   IN      O\n",
            "26          NaN       soldiers  NNS      O\n",
            "27          NaN         killed  VBN      O\n",
            "28          NaN             in   IN      O\n",
            "29          NaN            the   DT      O\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C92_hbJiPnmo"
      },
      "source": [
        "from itertools import chain\n",
        "def get_dict_map(data, token_or_tag):\n",
        "    tok2idx = {}\n",
        "    idx2tok = {}\n",
        "    \n",
        "    if token_or_tag == 'token':\n",
        "        vocab = list(set(data['Word'].to_list()))\n",
        "    else:\n",
        "        vocab = list(set(data['Tag'].to_list()))\n",
        "    \n",
        "    idx2tok = {idx:tok for  idx, tok in enumerate(vocab)}\n",
        "    tok2idx = {tok:idx for  idx, tok in enumerate(vocab)}\n",
        "    return tok2idx, idx2tok\n",
        "\n",
        "\n",
        "token2idx, idx2token = get_dict_map(data, 'token')\n",
        "tag2idx, idx2tag = get_dict_map(data, 'tag')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "x8mZc3hxPe2A",
        "outputId": "b331f6ca-de2a-43b2-98f0-7e0154ed0820"
      },
      "source": [
        "data['Word_idx'] = data['Word'].map(token2idx)\n",
        "data['Tag_idx'] = data['Tag'].map(tag2idx)\n",
        "data.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "      <th>Word_idx</th>\n",
              "      <th>Tag_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Thousands</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "      <td>25761</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "      <td>O</td>\n",
              "      <td>3981</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>demonstrators</td>\n",
              "      <td>NNS</td>\n",
              "      <td>O</td>\n",
              "      <td>1004</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>have</td>\n",
              "      <td>VBP</td>\n",
              "      <td>O</td>\n",
              "      <td>32966</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>marched</td>\n",
              "      <td>VBN</td>\n",
              "      <td>O</td>\n",
              "      <td>8056</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Sentence #           Word  POS Tag  Word_idx  Tag_idx\n",
              "0  Sentence: 1      Thousands  NNS   O     25761        0\n",
              "1          NaN             of   IN   O      3981        0\n",
              "2          NaN  demonstrators  NNS   O      1004        0\n",
              "3          NaN           have  VBP   O     32966        0\n",
              "4          NaN        marched  VBN   O      8056        0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoLGVYT3P_hH",
        "outputId": "aae065bb-873a-4526-aaf7-37e1ef16bd4d"
      },
      "source": [
        "data.isnull().sum()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentence #    1000616\n",
              "Word                0\n",
              "POS                 0\n",
              "Tag                 0\n",
              "Word_idx            0\n",
              "Tag_idx             0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBgODeujQEGi"
      },
      "source": [
        "data_fillna = data.fillna(method='ffill')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yWZHf7TjQSe0",
        "outputId": "42b566ee-7cfe-4372-8d67-6f0dbcfa38f4"
      },
      "source": [
        "data_fillna.isnull().sum()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sentence #    0\n",
              "Word          0\n",
              "POS           0\n",
              "Tag           0\n",
              "Word_idx      0\n",
              "Tag_idx       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "RfJZEaCzQVZW",
        "outputId": "367229fc-8ea8-4282-ff3b-387aab277d63"
      },
      "source": [
        "data_group = data_fillna.groupby(['Sentence #'],as_index=False)[['Word', 'POS', 'Tag', 'Word_idx', 'Tag_idx']].agg(lambda x: list(x))\n",
        "# Visualise data\n",
        "data_group.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence #</th>\n",
              "      <th>Word</th>\n",
              "      <th>POS</th>\n",
              "      <th>Tag</th>\n",
              "      <th>Word_idx</th>\n",
              "      <th>Tag_idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>[Thousands, of, demonstrators, have, marched, ...</td>\n",
              "      <td>[NNS, IN, NNS, VBP, VBN, IN, NNP, TO, VB, DT, ...</td>\n",
              "      <td>[O, O, O, O, O, O, B-geo, O, O, O, O, O, B-geo...</td>\n",
              "      <td>[25761, 3981, 1004, 32966, 8056, 18956, 13172,...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 4, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sentence: 10</td>\n",
              "      <td>[Iranian, officials, say, they, expect, to, ge...</td>\n",
              "      <td>[JJ, NNS, VBP, PRP, VBP, TO, VB, NN, TO, JJ, J...</td>\n",
              "      <td>[B-gpe, O, O, O, O, O, O, O, O, O, O, O, O, O,...</td>\n",
              "      <td>[1993, 8826, 19590, 1112, 21131, 268, 13155, 1...</td>\n",
              "      <td>[14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sentence: 100</td>\n",
              "      <td>[Helicopter, gunships, Saturday, pounded, mili...</td>\n",
              "      <td>[NN, NNS, NNP, VBD, JJ, NNS, IN, DT, NNP, JJ, ...</td>\n",
              "      <td>[O, O, B-tim, O, O, O, O, O, B-geo, O, O, O, O...</td>\n",
              "      <td>[14144, 33961, 21548, 18153, 14726, 6544, 6066...</td>\n",
              "      <td>[0, 0, 1, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 11,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Sentence: 1000</td>\n",
              "      <td>[They, left, after, a, tense, hour-long, stand...</td>\n",
              "      <td>[PRP, VBD, IN, DT, NN, JJ, NN, IN, NN, NNS, .]</td>\n",
              "      <td>[O, O, O, O, O, O, O, O, O, O, O]</td>\n",
              "      <td>[22432, 32008, 14811, 15235, 32549, 29261, 242...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sentence: 10000</td>\n",
              "      <td>[U.N., relief, coordinator, Jan, Egeland, said...</td>\n",
              "      <td>[NNP, NN, NN, NNP, NNP, VBD, NNP, ,, NNP, ,, J...</td>\n",
              "      <td>[B-geo, O, O, B-per, I-per, O, B-tim, O, B-geo...</td>\n",
              "      <td>[20411, 580, 23403, 32424, 11771, 6639, 222, 3...</td>\n",
              "      <td>[4, 0, 0, 16, 6, 0, 1, 0, 4, 0, 14, 0, 14, 0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Sentence #  ...                                            Tag_idx\n",
              "0      Sentence: 1  ...  [0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 4, 0, 0, ...\n",
              "1     Sentence: 10  ...  [14, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...\n",
              "2    Sentence: 100  ...  [0, 0, 1, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 11,...\n",
              "3   Sentence: 1000  ...                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
              "4  Sentence: 10000  ...  [4, 0, 0, 16, 6, 0, 1, 0, 4, 0, 14, 0, 14, 0, ...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wqg5NL0RDwk",
        "outputId": "acc2e2e3-dac8-4888-8e7c-7bea7eec66d7"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "\n",
        "\n",
        "def get_pad_train_test_val(data_group, data):\n",
        "\n",
        "    #get max token and tag length\n",
        "    n_token = len(list(set(data['Word'].to_list())))\n",
        "    n_tag = len(list(set(data['Tag'].to_list())))\n",
        "\n",
        "    #Pad tokens (X var)    \n",
        "    tokens = data_group['Word_idx'].tolist()\n",
        "    maxlen = max([len(s) for s in tokens])\n",
        "    pad_tokens = pad_sequences(tokens, maxlen=maxlen, dtype='int32', padding='post', value= n_token - 1)\n",
        "\n",
        "    #Pad Tags (y var) and convert it into one hot encoding\n",
        "    tags = data_group['Tag_idx'].tolist()\n",
        "    pad_tags = pad_sequences(tags, maxlen=maxlen, dtype='int32', padding='post', value= tag2idx[\"O\"])\n",
        "    n_tags = len(tag2idx)\n",
        "    pad_tags = [to_categorical(i, num_classes=n_tags) for i in pad_tags]\n",
        "    \n",
        "    #Split train, test and validation set\n",
        "    tokens_, test_tokens, tags_, test_tags = train_test_split(pad_tokens, pad_tags, test_size=0.1, train_size=0.9, random_state=2020)\n",
        "    train_tokens, val_tokens, train_tags, val_tags = train_test_split(tokens_,tags_,test_size = 0.25,train_size =0.75, random_state=2020)\n",
        "\n",
        "    print(\n",
        "        'train_tokens length:', len(train_tokens),\n",
        "        '\\ntrain_tokens length:', len(train_tokens),\n",
        "        '\\ntest_tokens length:', len(test_tokens),\n",
        "        '\\ntest_tags:', len(test_tags),\n",
        "        '\\nval_tokens:', len(val_tokens),\n",
        "        '\\nval_tags:', len(val_tags),\n",
        "    )\n",
        "    \n",
        "    return train_tokens, val_tokens, test_tokens, train_tags, val_tags, test_tags\n",
        "\n",
        "train_tokens, val_tokens, test_tokens, train_tags, val_tags, test_tags = get_pad_train_test_val(data_group, data)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_tokens length: 32372 \n",
            "train_tokens length: 32372 \n",
            "test_tokens length: 4796 \n",
            "test_tags: 4796 \n",
            "val_tokens: 10791 \n",
            "val_tags: 10791\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6eOt8h1WG8A",
        "outputId": "fd015376-ad3b-44af-8ad8-2ca07e587271"
      },
      "source": [
        "print(train_tokens[0])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[15049 15237 11884 19223 10834 15956 31562 10693  7306 30940 15235 19886\n",
            "  1302   268 16016 31562 18832 20486  5704 10578 17173 27145  7481 29033\n",
            " 21891 23177   268 17317  6066 14926 18813 35177 35177 35177 35177 35177\n",
            " 35177 35177 35177 35177 35177 35177 35177 35177 35177 35177 35177 35177\n",
            " 35177 35177 35177 35177 35177 35177 35177 35177 35177 35177 35177 35177\n",
            " 35177 35177 35177 35177 35177 35177 35177 35177 35177 35177 35177 35177\n",
            " 35177 35177 35177 35177 35177 35177 35177 35177 35177 35177 35177 35177\n",
            " 35177 35177 35177 35177 35177 35177 35177 35177 35177 35177 35177 35177\n",
            " 35177 35177 35177 35177 35177 35177 35177 35177]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HrVhjf5oap3_"
      },
      "source": [
        "# **Prepare the input parameters for Embedding Layer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QiwPll0RdHa",
        "outputId": "0d3a7be8-0efc-43fe-f872-8794a13f7dfd"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow\n",
        "from tensorflow.keras import Sequential, Model, Input\n",
        "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "from numpy.random import seed\n",
        "seed(1)\n",
        "tensorflow.random.set_seed(2)\n",
        "\n",
        "input_dim = len(list(set(data['Word'].to_list())))+1\n",
        "output_dim = 64\n",
        "input_length = max([len(s) for s in data_group['Word_idx'].tolist()])\n",
        "n_tags = len(tag2idx)\n",
        "print('input_dim: ', input_dim, '\\noutput_dim: ', output_dim, '\\ninput_length: ', input_length, '\\nn_tags: ', n_tags)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input_dim:  35179 \n",
            "output_dim:  64 \n",
            "input_length:  104 \n",
            "n_tags:  17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vx3UROqoRp9E"
      },
      "source": [
        "# **Build Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCYce_wdRsx8"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow\n",
        "from tensorflow.keras import Sequential, Model, Input\n",
        "from tensorflow.keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OtIvMJ_RvgP"
      },
      "source": [
        "def get_bilstm_lstm_model():\n",
        "  model = Sequential()\n",
        "  \n",
        "  # Add Embedding layer\n",
        "  model.add(Embedding(input_dim=input_dim, output_dim=140, input_length=140))\n",
        "  model.add(Dropout(0.2))\n",
        "  \n",
        "  #Add bidirectional LSTM\n",
        "  model.add(Bidirectional(LSTM(units=output_dim, return_sequences=True, dropout=0.2, recurrent_dropout=0.1), merge_mode = 'concat'))\n",
        "  \n",
        "  # Add timeDistributed Layer\n",
        "  model.add(TimeDistributed(Dense(n_tags, activation=\"softmax\")))\n",
        "  \n",
        "  #Optimiser\n",
        "  # adam = k.optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999)\n",
        "  \n",
        "  # Compile model\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  \n",
        "  \n",
        "  return model"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4W7uunnTSfBx"
      },
      "source": [
        "def train_model(X, y, model):\n",
        "    loss = list()\n",
        "    for i in range(25):\n",
        "        # fit model for one epoch on this sequence\n",
        "        hist = model.fit(X, y, batch_size=1000, verbose=1, epochs=1, validation_split=0.2)\n",
        "        loss.append(hist.history['loss'][0])\n",
        "    return loss"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCww9sw9SgsZ",
        "outputId": "9ef695b9-d507-42af-cd56-08d44b43bc4c"
      },
      "source": [
        "results = pd.DataFrame()\n",
        "model_bilstm_lstm = get_bilstm_lstm_model()\n",
        "plot_model(model_bilstm_lstm)\n",
        "results['with_add_lstm'] = train_model(train_tokens, np.array(train_tags), model_bilstm_lstm)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 140, 140)          4925060   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 140, 140)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 140, 128)          104960    \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 140, 17)           2193      \n",
            "=================================================================\n",
            "Total params: 5,032,213\n",
            "Trainable params: 5,032,213\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 140) for input KerasTensor(type_spec=TensorSpec(shape=(None, 140), dtype=tf.float32, name='embedding_1_input'), name='embedding_1_input', description=\"created by layer 'embedding_1_input'\"), but it was called on an input with incompatible shape (None, 104).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 140) for input KerasTensor(type_spec=TensorSpec(shape=(None, 140), dtype=tf.float32, name='embedding_1_input'), name='embedding_1_input', description=\"created by layer 'embedding_1_input'\"), but it was called on an input with incompatible shape (None, 104).\n",
            "26/26 [==============================] - ETA: 0s - loss: 1.2249 - accuracy: 0.9166WARNING:tensorflow:Model was constructed with shape (None, 140) for input KerasTensor(type_spec=TensorSpec(shape=(None, 140), dtype=tf.float32, name='embedding_1_input'), name='embedding_1_input', description=\"created by layer 'embedding_1_input'\"), but it was called on an input with incompatible shape (None, 104).\n",
            "26/26 [==============================] - 32s 953ms/step - loss: 1.2249 - accuracy: 0.9166 - val_loss: 0.2303 - val_accuracy: 0.9681\n",
            "26/26 [==============================] - 24s 917ms/step - loss: 0.2167 - accuracy: 0.9677 - val_loss: 0.1898 - val_accuracy: 0.9681\n",
            "26/26 [==============================] - 24s 923ms/step - loss: 0.1827 - accuracy: 0.9677 - val_loss: 0.1712 - val_accuracy: 0.9681\n",
            "26/26 [==============================] - 24s 933ms/step - loss: 0.1626 - accuracy: 0.9677 - val_loss: 0.1501 - val_accuracy: 0.9681\n",
            "26/26 [==============================] - 24s 933ms/step - loss: 0.1405 - accuracy: 0.9677 - val_loss: 0.1282 - val_accuracy: 0.9681\n",
            "26/26 [==============================] - 24s 919ms/step - loss: 0.1193 - accuracy: 0.9677 - val_loss: 0.1088 - val_accuracy: 0.9682\n",
            "26/26 [==============================] - 24s 930ms/step - loss: 0.1026 - accuracy: 0.9691 - val_loss: 0.0960 - val_accuracy: 0.9714\n",
            "26/26 [==============================] - 24s 939ms/step - loss: 0.0921 - accuracy: 0.9723 - val_loss: 0.0886 - val_accuracy: 0.9732\n",
            "26/26 [==============================] - 24s 925ms/step - loss: 0.0855 - accuracy: 0.9734 - val_loss: 0.0837 - val_accuracy: 0.9743\n",
            "26/26 [==============================] - 24s 930ms/step - loss: 0.0807 - accuracy: 0.9746 - val_loss: 0.0799 - val_accuracy: 0.9756\n",
            "26/26 [==============================] - 24s 928ms/step - loss: 0.0765 - accuracy: 0.9762 - val_loss: 0.0762 - val_accuracy: 0.9773\n",
            "26/26 [==============================] - 24s 928ms/step - loss: 0.0724 - accuracy: 0.9785 - val_loss: 0.0723 - val_accuracy: 0.9803\n",
            "26/26 [==============================] - 24s 923ms/step - loss: 0.0680 - accuracy: 0.9813 - val_loss: 0.0680 - val_accuracy: 0.9826\n",
            "26/26 [==============================] - 24s 926ms/step - loss: 0.0632 - accuracy: 0.9835 - val_loss: 0.0634 - val_accuracy: 0.9843\n",
            "26/26 [==============================] - 24s 932ms/step - loss: 0.0582 - accuracy: 0.9854 - val_loss: 0.0588 - val_accuracy: 0.9858\n",
            "26/26 [==============================] - 24s 930ms/step - loss: 0.0533 - accuracy: 0.9872 - val_loss: 0.0542 - val_accuracy: 0.9874\n",
            "26/26 [==============================] - 24s 919ms/step - loss: 0.0484 - accuracy: 0.9889 - val_loss: 0.0499 - val_accuracy: 0.9885\n",
            "26/26 [==============================] - 25s 947ms/step - loss: 0.0438 - accuracy: 0.9900 - val_loss: 0.0460 - val_accuracy: 0.9891\n",
            "26/26 [==============================] - 24s 928ms/step - loss: 0.0398 - accuracy: 0.9906 - val_loss: 0.0429 - val_accuracy: 0.9895\n",
            "26/26 [==============================] - 24s 926ms/step - loss: 0.0365 - accuracy: 0.9912 - val_loss: 0.0405 - val_accuracy: 0.9898\n",
            "26/26 [==============================] - 24s 937ms/step - loss: 0.0337 - accuracy: 0.9916 - val_loss: 0.0386 - val_accuracy: 0.9901\n",
            "26/26 [==============================] - 24s 934ms/step - loss: 0.0315 - accuracy: 0.9921 - val_loss: 0.0371 - val_accuracy: 0.9904\n",
            "26/26 [==============================] - 24s 930ms/step - loss: 0.0295 - accuracy: 0.9925 - val_loss: 0.0358 - val_accuracy: 0.9907\n",
            "26/26 [==============================] - 24s 937ms/step - loss: 0.0278 - accuracy: 0.9928 - val_loss: 0.0349 - val_accuracy: 0.9909\n",
            "26/26 [==============================] - 24s 916ms/step - loss: 0.0264 - accuracy: 0.9931 - val_loss: 0.0341 - val_accuracy: 0.9911\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMZdCcJaTIlU"
      },
      "source": [
        "model_bilstm_lstm.save('/content/gdrive/MyDrive/Sequence Learning Assignments/NER_model.h5')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKiuKCSrVnMI",
        "outputId": "0dbfaf32-1a95-4d00-ef99-86076570728e"
      },
      "source": [
        "from tensorflow import keras\n",
        "NER_model =keras.models.load_model('/content/gdrive/MyDrive/Sequence Learning Assignments/NER_model.h5')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37wYhjeNVwUE",
        "outputId": "5617e757-aec0-47a8-bbb8-31801aa4f441"
      },
      "source": [
        "NER_model.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 140, 140)          4925060   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 140, 140)          0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 140, 128)          104960    \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 140, 17)           2193      \n",
            "=================================================================\n",
            "Total params: 5,032,213\n",
            "Trainable params: 5,032,213\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}